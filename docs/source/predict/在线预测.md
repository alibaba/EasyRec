# Online Prediction

如果您希望将模型文件部署到自己的生产环境中，可以用 [tensorflow serving](https://github.com/tensorflow/serving) 的方式部署。

这里，我们推荐使用阿里云上的[模型在线服务(PAI-EAS)](https://help.aliyun.com/document_detail/113696.html) 来进行在线推理，具体参考:[EAS部署模型](https://help.aliyun.com/document_detail/110985.html) 的控制台上传模型部分。

部署模型示例:

```bash
#!/bin/bash
bizdate=$1

cat << EOF > eas_config_rank.json
{
 "name": "dbmtl_rank_ml",
 "generate_token": "true",
 "model_path": "oss://XXX/${bizdate}/export/best/",
 "processor": "tensorflow_cpu",
 "oss_endpoint": "oss-us-west-1.aliyuncs.com",
 "token": "XXXX",
 "metadata":{
    "region": "us-west-1",
    "instance": 4,
    "cpu": 8,
    "gpu": 0,
    "memory": 8000
 }
}
EOF
cat eas_config_rank.json

# 创建服务
# /home/admin/usertools/tools/eascmd -i <AccessKeyID> -k <AccessKeySecret> \
# -e pai-eas.us-west-1.aliyuncs.com create eas_config_rank.json

# 更新服务
echo "-------------------更新服务-------------------"
/home/admin/usertools/tools/eascmd -i <AccessKeyID> -k <AccessKeySecret> \
-e pai-eas.us-west-1.aliyuncs.com \
modify dbmtl_rank_ml -s eas_config_rank.json

status=$?

# 查看服务
echo "-------------------查看服务-------------------"
/home/admin/usertools/tools/eascmd -i <AccessKeyID> -k <AccessKeySecret>  \
-e pai-eas.us-west-1.aliyuncs.com desc dbmtl_rank_ml

exit ${status}
```

模型部署到线上后，线上需构造请求数据，具体请参考：[TensorFlow服务请求构造](https://help.aliyun.com/document_detail/111055.html)

如果您用到了fg，可以参考：[RTP FG的预测部分](../feature/rtp_fg.md/)

如果需要用到PaiRec进行在线推荐服务，可以参考：[PaiRec部署服务](http://pai-vision-data-hz.oss-cn-zhangjiakou.aliyuncs.com/pairec/docs/pairec/html/deploy/eas.html)
